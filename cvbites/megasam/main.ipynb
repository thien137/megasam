{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import os.path as osp\n",
    "import shutil \n",
    "from dataclasses import asdict, dataclass \n",
    "from datetime import datetime \n",
    "from typing import Annotated \n",
    "\n",
    "import numpy as np \n",
    "import torch \n",
    "import tyro \n",
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MegaSAM\n",
    "\n",
    "Given an unconstrained, continuous video sequence \n",
    "\n",
    "$$\\mathcal{V} = \\{ I_i \\in \\mathcal{R}^{H \\times W} \\}^N_{i=1}$$\n",
    "\n",
    "We want to estimate: \n",
    "\n",
    "- Camera Poses: $\\hat{\\textbf{G}_i} \\in SE(3)$\n",
    "- Focal Length: $\\hat{f}$ (if unknown)\n",
    "- Dense Video Depth Maps: $\\mathcal{D} = \\{ \\hat{D}_i \\}^N_{i=1}$\n",
    "\n",
    "# System Overview\n",
    "\n",
    "We separate the problem of camera and scene structure estimation into two stages, in the spirit of a conventional SfM pipeline.\n",
    "\n",
    "1. Estimate camera poses $\\hat{\\textbf{G}_i}$, focal length $\\hat{f}$, and low-resolution disparity $\\hat{d}$ from the input monocular video through differentiable Bundle Adjustment (BA), where we intialize $\\hat{\\textbf{d}}$ with monocular depth maps predicted from off-the-shelf models, e.g. Unidepth and Depth-Anything\n",
    "    \n",
    "2. Fix estimated camera parameters and perform first-order optimization over depth and uncertainty maps by enforcing flow and depth losses induced by pairwise 2D optical flows.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"assets/flow_diagram.png\" alt=\"Flow Diagram\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function\n",
    "\n",
    "The objective consists of three main cost functions\n",
    "$$C_{cvd} = w_{\\text{flow}}C_{\\text{flow}} + w_{\\text{temp}}C_{\\text{temp}} + w_{\\text{temp}}C_{\\text{temp}}$$\n",
    "\n",
    "For each selected pair $(I_i, I_j)$, flow reprojection loss $C_{\\text{flow}}$ compares $l_1$ loss weighted by the uncertainty $\\hat{M}_i$ between flows $\\text{flow}_{i\\rightarrow j}$ from RAFT and the correspondences $\\textbf{u}_{ij}$ induced by our estimated camera motion and disparity through a multi-view constraint \n",
    "\n",
    "$$C^{i \\rightarrow j}_{\\text{flow}} = \\hat{M}_i \\|\\textbf{u}_{ij} - \\textbf{p}_i\\|_1  + \\log{(\\frac{1}{\\hat{M}_i})}$$\n",
    "\n",
    "$$\\textbf{u}_{ij} = \\pi \\left(\\hat{G}_{ij} \\circ \\pi^{-1} (\\textbf{p}_i, \\hat{D}_i, K^{-1}), K \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
